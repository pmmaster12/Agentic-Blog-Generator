{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d84ab83",
   "metadata": {},
   "source": [
    "## importing Library and environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41061812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import operator\n",
    "import os\n",
    "import re\n",
    "from datetime import date, timedelta\n",
    "from pathlib import Path\n",
    "from typing import TypedDict, List, Optional, Literal, Annotated\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.types import Send\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fbb02a",
   "metadata": {},
   "source": [
    "## Pydantic Schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e459efbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------\n",
    "# 1) Schemas\n",
    "#----------------------------\n",
    "class Task(BaseModel):\n",
    "    id: int\n",
    "    title: str\n",
    "    goal: str = Field(\n",
    "        ...,\n",
    "        description = \"One sentence describing what the reader should be able to do/understand after this section.\",\n",
    "    )\n",
    "    bullets: List[str] = Field(\n",
    "        ...,\n",
    "        min_length=3,\n",
    "        max_length=6,\n",
    "        description=\"3–6 concrete, non-overlapping subpoints to cover in this section.\",\n",
    "    )\n",
    "    target_words: int = Field(..., description=\"Target word count for this section (120–550).\")\n",
    "    \n",
    "    tags: List[str] = Field(default_factory=list)\n",
    "    requires_research: bool = False\n",
    "    requires_citations: bool = False\n",
    "    requires_code: bool = False\n",
    "    \n",
    "\n",
    "class Plan(BaseModel):\n",
    "    blog_title: str\n",
    "    audience: str\n",
    "    tone: str\n",
    "    blog_kind: Literal[\"explainer\", \"tutorial\", \"news_roundup\", \"comparison\", \"system_design\"] = \"explainer\"\n",
    "    constraints: List[str] = Field(default_factory=list)\n",
    "    tasks: List[Task]\n",
    "\n",
    "class EvidenceItem(BaseModel):\n",
    "    title: str\n",
    "    url: str\n",
    "    published_at: Optional[str] = None  # keep if Tavily provides; DO NOT rely on it\n",
    "    snippet: Optional[str] = None\n",
    "    source: Optional[str] = None\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a0e337",
   "metadata": {},
   "source": [
    "## LangGraph State Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c50add4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    topic: str\n",
    "    \n",
    "    #routing / research\n",
    "    mode: str\n",
    "    need_research: bool\n",
    "    queries: List[str]\n",
    "    evidence: List[EvidenceItem]\n",
    "    plan: Optional[Plan]\n",
    "    \n",
    "    #workers\n",
    "    sections: Annotated[List[tuple[int,str]], operator.add] # (task_id, section_md)\n",
    "    \n",
    "    #reducer/image\n",
    "    merged_md: str\n",
    "    md_with_placeholders: str\n",
    "    image_specs: List[dict]\n",
    "    final: str\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf51a72",
   "metadata": {},
   "source": [
    "## OpenAI Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70bd054c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    api_key = os.getenv(\"GEMINI_API_KEY\"),\n",
    "    base_url= \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121268da",
   "metadata": {},
   "source": [
    "## LangGraph Graph Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "12981df0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'research_node' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m#added nodes\u001b[39;00m\n\u001b[32m      7\u001b[39m g.add_node(\u001b[33m\"\u001b[39m\u001b[33mrouter\u001b[39m\u001b[33m\"\u001b[39m, router_node)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m g.add_node(\u001b[33m\"\u001b[39m\u001b[33mresearch\u001b[39m\u001b[33m\"\u001b[39m, \u001b[43mresearch_node\u001b[49m)\n\u001b[32m      9\u001b[39m g.add_node(\u001b[33m\"\u001b[39m\u001b[33morchestrator\u001b[39m\u001b[33m\"\u001b[39m, orchestrator_node)\n\u001b[32m     10\u001b[39m g.add_node(\u001b[33m\"\u001b[39m\u001b[33mworker\u001b[39m\u001b[33m\"\u001b[39m, worker_node)\n",
      "\u001b[31mNameError\u001b[39m: name 'research_node' is not defined"
     ]
    }
   ],
   "source": [
    "#----------------------\n",
    "# build main graph\n",
    "#-----------------------\n",
    "g = StateGraph(State)\n",
    "\n",
    "#added nodes\n",
    "g.add_node(\"router\", router_node)\n",
    "g.add_node(\"research\", research_node)\n",
    "g.add_node(\"orchestrator\", orchestrator_node)\n",
    "g.add_node(\"worker\", worker_node)\n",
    "g.add_node(\"reducer\", reducer_subgraph)\n",
    "\n",
    "# graph construction by joining edges\n",
    "g.add_edge(START, \"router\")\n",
    "g.add_conditional_edges(\"router\", route_next, {\"research\":\"research\",\"orchestrator\":\"orchestrator\"})\n",
    "g.add_edge(\"research\", \"orchestrator\")\n",
    "g.add_conditional_edges(\"orchestrator\", fanout, [\"worker\"])\n",
    "g.add_edge(\"worker\", \"reducer\")\n",
    "g.add_edge(\"reducer\",END)\n",
    "\n",
    "app = g.compile()\n",
    "app\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9bd4454e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def router_node(state: State) -> dict:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc5b4a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
