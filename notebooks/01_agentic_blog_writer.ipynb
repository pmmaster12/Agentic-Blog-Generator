{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d84ab83",
   "metadata": {},
   "source": [
    "## importing Library and environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41061812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import operator\n",
    "import os\n",
    "import re\n",
    "from datetime import date, timedelta\n",
    "from pathlib import Path\n",
    "from typing import TypedDict, List, Optional, Literal, Annotated\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.types import Send\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fbb02a",
   "metadata": {},
   "source": [
    "## Pydantic Schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e459efbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------\n",
    "# 1) Schemas\n",
    "#----------------------------\n",
    "class Task(BaseModel):\n",
    "    id: int\n",
    "    title: str\n",
    "    goal: str = Field(\n",
    "        ...,\n",
    "        description = \"One sentence describing what the reader should be able to do/understand after this section.\",\n",
    "    )\n",
    "    bullets: List[str] = Field(\n",
    "        ...,\n",
    "        min_length=3,\n",
    "        max_length=6,\n",
    "        description=\"3–6 concrete, non-overlapping subpoints to cover in this section.\",\n",
    "    )\n",
    "    target_words: int = Field(..., description=\"Target word count for this section (120–550).\")\n",
    "    \n",
    "    tags: List[str] = Field(default_factory=list)\n",
    "    requires_research: bool = False\n",
    "    requires_citations: bool = False\n",
    "    requires_code: bool = False\n",
    "    \n",
    "\n",
    "class Plan(BaseModel):\n",
    "    blog_title: str\n",
    "    audience: str\n",
    "    tone: str\n",
    "    blog_kind: Literal[\"explainer\", \"tutorial\", \"news_roundup\", \"comparison\", \"system_design\"] = \"explainer\"\n",
    "    constraints: List[str] = Field(default_factory=list)\n",
    "    tasks: List[Task]\n",
    "\n",
    "class EvidenceItem(BaseModel):\n",
    "    title: str\n",
    "    url: str\n",
    "    published_at: Optional[str] = None  # keep if Tavily provides; DO NOT rely on it\n",
    "    snippet: Optional[str] = None\n",
    "    source: Optional[str] = None\n",
    "    \n",
    "class RouterDecision(BaseModel):\n",
    "    needs_research: bool\n",
    "    mode: Literal[\"closed_book\", \"hybrid\", \"open_book\"]\n",
    "    queries: List[str] = Field(default_factory=list)\n",
    "\n",
    "class EvidencePack(BaseModel):\n",
    "    evidence: List[EvidenceItem] = Field(default_factory=list)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a0e337",
   "metadata": {},
   "source": [
    "## LangGraph State Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c50add4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    topic: str\n",
    "    \n",
    "    #routing / research\n",
    "    mode: str\n",
    "    need_research: bool\n",
    "    queries: List[str]\n",
    "    evidence: List[EvidenceItem]\n",
    "    plan: Optional[Plan]\n",
    "    \n",
    "    #workers\n",
    "    sections: Annotated[List[tuple[int,str]], operator.add] # (task_id, section_md)\n",
    "    \n",
    "    #reducer/image\n",
    "    merged_md: str\n",
    "    md_with_placeholders: str\n",
    "    image_specs: List[dict]\n",
    "    final: str\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf51a72",
   "metadata": {},
   "source": [
    "## OpenAI Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70bd054c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=\"gemini-3-flash-preview\",\n",
    "    api_key = os.getenv(\"GEMINI_API_KEY\"),\n",
    "    base_url= \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64ed32d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"J'adore la programmation.\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that translates English to French. Translate the user sentence.\",\n",
    "    ),\n",
    "    (\"human\", \"I love programming.\"),\n",
    "]\n",
    "ai_msg = llm.invoke(messages)\n",
    "ai_msg.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121268da",
   "metadata": {},
   "source": [
    "## LangGraph Graph Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12981df0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'orchestrator_node' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m g.add_node(\u001b[33m\"\u001b[39m\u001b[33mrouter\u001b[39m\u001b[33m\"\u001b[39m, router_node)\n\u001b[32m      8\u001b[39m g.add_node(\u001b[33m\"\u001b[39m\u001b[33mresearch\u001b[39m\u001b[33m\"\u001b[39m, research_node)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m g.add_node(\u001b[33m\"\u001b[39m\u001b[33morchestrator\u001b[39m\u001b[33m\"\u001b[39m, \u001b[43morchestrator_node\u001b[49m)\n\u001b[32m     10\u001b[39m g.add_node(\u001b[33m\"\u001b[39m\u001b[33mworker\u001b[39m\u001b[33m\"\u001b[39m, worker_node)\n\u001b[32m     11\u001b[39m g.add_node(\u001b[33m\"\u001b[39m\u001b[33mreducer\u001b[39m\u001b[33m\"\u001b[39m, reducer_subgraph)\n",
      "\u001b[31mNameError\u001b[39m: name 'orchestrator_node' is not defined"
     ]
    }
   ],
   "source": [
    "#----------------------\n",
    "# build main graph\n",
    "#-----------------------\n",
    "g = StateGraph(State)\n",
    "\n",
    "#added nodes\n",
    "g.add_node(\"router\", router_node)\n",
    "g.add_node(\"research\", research_node)\n",
    "g.add_node(\"orchestrator\", orchestrator_node)\n",
    "g.add_node(\"worker\", worker_node)\n",
    "g.add_node(\"reducer\", reducer_subgraph)\n",
    "\n",
    "# graph construction by joining edges\n",
    "g.add_edge(START, \"router\")\n",
    "g.add_conditional_edges(\"router\", route_next, {\"research\":\"research\",\"orchestrator\":\"orchestrator\"})\n",
    "g.add_edge(\"research\", \"orchestrator\")\n",
    "g.add_conditional_edges(\"orchestrator\", fanout, [\"worker\"])\n",
    "g.add_edge(\"worker\", \"reducer\")\n",
    "g.add_edge(\"reducer\",END)\n",
    "\n",
    "app = g.compile()\n",
    "app\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bd4454e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROUTER_SYSTEM =  \"\"\"You are a routing module for a technical blog planner.\n",
    "\n",
    "Decide whether web research is needed BEFORE planning.\n",
    "\n",
    "Modes:\n",
    "- closed_book (needs_research=false):\n",
    "  Evergreen topics where correctness does not depend on recent facts (concepts, fundamentals).\n",
    "- hybrid (needs_research=true):\n",
    "  Mostly evergreen but needs up-to-date examples/tools/models to be useful.\n",
    "- open_book (needs_research=true):\n",
    "  Mostly volatile: weekly roundups, \"this week\", \"latest\", rankings, pricing, policy/regulation.\n",
    "\n",
    "If needs_research=true:\n",
    "- Output 3–10 high-signal queries.\n",
    "- Queries should be scoped and specific (avoid generic queries like just \"AI\" or \"LLM\").\n",
    "- If user asked for \"last week/this week/latest\", reflect that constraint IN THE QUERIES.\n",
    "\"\"\"\n",
    "\n",
    "def router_node(state: State) -> dict:\n",
    "    \n",
    "    topic = state['topic']\n",
    "    decider = llm.with_structured_output(RouterDecision)\n",
    "    decision = decider.invoke(\n",
    "      [\n",
    "        SystemMessage(content = ROUTER_SYSTEM),\n",
    "        HumanMessage(content = f\"Topic: {topic}\"),\n",
    "      ]\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "      \"needs_research\": decision.needs_research,\n",
    "      \"mode\": decision.mode,\n",
    "      \"queries\": decision.queries,\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfc5b4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_next(state : State) -> str:\n",
    "    return \"research\" if state[\"need_research\"] else \"orchestrator\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbacc527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "#  Research (Tavily) \n",
    "# -----------------------------\n",
    "\n",
    "def tavily_search(query: str, max_results: int = 5) -> List[dict]:\n",
    "    \n",
    "    tool = TavilySearchResults(max_results=max_results)\n",
    "    results = tool.invoke({\"query\": query})\n",
    "    \n",
    "    normalized: List[dict] = []\n",
    "    for r in results or []:\n",
    "        normalized.append(\n",
    "            {\n",
    "                \"title\": r.get(\"title\") or \"\",\n",
    "                \"uu rl\": r.get(\"url\") or \"\",\n",
    "                \"snippet\": r.get(\"content\") or r.get(\"snippet\") or \"\",\n",
    "                \"published_at\": r.get(\"published_date\") or r.get(\"published_at\"),\n",
    "                \"source\": r.get(\"source\"),\n",
    "            }\n",
    "        )\n",
    "    return normalized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "617a42c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------------#\n",
    "#                  Research ( Using Tavily Search Engine API)\n",
    "# -------------------------------------------------------------------------------#\n",
    "RESEARCH_SYSTEM = \"\"\"You are a research synthesizer for technical writing.\n",
    "\n",
    "Given raw web search results, produce a deduplicated list of EvidenceItem objects.\n",
    "\n",
    "Rules:\n",
    "- Only include items with a non-empty url.\n",
    "- Prefer relevant + authoritative sources (company blogs, docs, reputable outlets).\n",
    "- If a published date is explicitly present in the result payload, keep it as YYYY-MM-DD.\n",
    "  If missing or unclear, set published_at=null. Do NOT guess.\n",
    "- Keep snippets short.\n",
    "- Deduplicate by URL.\n",
    "\"\"\"\n",
    "\n",
    "def research_node(state : State) -> dict:\n",
    "      \n",
    "      #  take the first 10 queries from state  \n",
    "      queries = (state.get(\"queries\",[]) or [])\n",
    "      max_result = 6\n",
    "      \n",
    "      raw_results: List[dict] = []\n",
    "      \n",
    "      for q in queries:\n",
    "            raw_results.extend(tavily_search(q,max_result= max_result))\n",
    "      \n",
    "      if not raw_results:\n",
    "            return {\"evidence\": []}\n",
    "      \n",
    "      extractor = llm.with_structured_output(EvidencePack)\n",
    "      \n",
    "      pack = extractor.invoke(\n",
    "            [\n",
    "                  SystemMessage(content = RESEARCH_SYSTEM),\n",
    "                  HumanMessage(content = f\"Raw results:\\n{raw_results}\"),\n",
    "            ]\n",
    "      )\n",
    "      \n",
    "      # dedupicate by URL\n",
    "      dedup = {}\n",
    "      for e in pack.evidence:\n",
    "            if e.url:\n",
    "                  dedup[e.url] = e\n",
    "                  \n",
    "      return {\n",
    "            \"evidence\" : list(dedup.values())\n",
    "      }\n",
    "      \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6fe5861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 5) Orchestrator (Plan)\n",
    "# -----------------------------\n",
    "\n",
    "ORCH_SYSTEM = \"\"\"You are a senior technical writer and developer advocate.\n",
    "Your job is to produce a highly actionable outline for a technical blog post.\n",
    "\n",
    "Hard requirements:\n",
    "- Create 5–9 sections (tasks) suitable for the topic and audience.\n",
    "- Each task must include:\n",
    "  1) goal (1 sentence)\n",
    "  2) 3–6 bullets that are concrete, specific, and non-overlapping\n",
    "  3) target word count (120–550)\n",
    "\n",
    "Quality bar:\n",
    "- Assume the reader is a developer; use correct terminology.\n",
    "- Bullets must be actionable: build/compare/measure/verify/debug.\n",
    "- Ensure the overall plan includes at least 2 of these somewhere:\n",
    "  * minimal code sketch / MWE (set requires_code=True for that section)\n",
    "  * edge cases / failure modes\n",
    "  * performance/cost considerations\n",
    "  * security/privacy considerations (if relevant)\n",
    "  * debugging/observability tips\n",
    "\n",
    "Grounding rules:\n",
    "- Mode closed_book: keep it evergreen; do not depend on evidence.\n",
    "- Mode hybrid:\n",
    "  - Use evidence for up-to-date examples (models/tools/releases) in bullets.\n",
    "  - Mark sections using fresh info as requires_research=True and requires_citations=True.\n",
    "- Mode open_book:\n",
    "  - Set blog_kind = \"news_roundup\".\n",
    "  - Every section is about summarizing events + implications.\n",
    "  - DO NOT include tutorial/how-to sections unless user explicitly asked for that.\n",
    "  - If evidence is empty or insufficient, create a plan that transparently says \"insufficient sources\"\n",
    "    and includes only what can be supported.\n",
    "\n",
    "Output must strictly match the Plan schema.\n",
    "\"\"\"\n",
    "\n",
    "def orchestrator_node(state: State) -> dict: \n",
    "    \n",
    "    planner = llm.with_structured_output(Plan)\n",
    "    \n",
    "    evidence = state.get(\"evidence\", [])\n",
    "    mode = state.get(\"mode\",\"closed_book\")\n",
    "    \n",
    "    plan = planner.invoke(\n",
    "      [\n",
    "        SystemMessage(content = ORCH_SYSTEM),\n",
    "        HumanMessage(\n",
    "          content = (\n",
    "                    f\"Topic: {state['topic']}\\n\"\n",
    "                    f\"Mode: {mode}\\n\\n\"\n",
    "                    f\"Evidence (ONLY use for fresh claims; may be empty):\\n\"\n",
    "                    f\"{[e.model_dump() for e in evidence][:16]}\"\n",
    "          )\n",
    "        ),\n",
    "      ]\n",
    "    )\n",
    "    \n",
    "    return {\"plan\": plan}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8786e923",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------------------------------------------------------#\n",
    "#---------------------------------FANOUT-CODE FOR AUTO SCALING AND PARALLISM--------------------------------#\n",
    "\n",
    "def fanout(state: State):\n",
    "    return [\n",
    "        Send(\n",
    "            \"worker\",\n",
    "            {\n",
    "                \"task\": task.model_dump(),\n",
    "                \"topic\": state[\"topic\"],\n",
    "                \"mode\": state[\"mode\"],\n",
    "                \"plan\": state[\"plan\"].model_dump(),\n",
    "                \"evidence\": [e.model_dump() for e in state.get(\"evidence\", [])],\n",
    "                \n",
    "            },\n",
    "        )\n",
    "        for task in state[\"plan\"].tasks\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee703fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
